{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline for running MD and labelme \n",
    "\n",
    "This pipeline is built by testing on an arbitrarily-chosen subset of the NZ trail cam dataset: https://lila.science/datasets/nz-trailcams\n",
    "\n",
    "This notebook involves two conda environments (for some reason, possibly to do with opencv-python, installing megadetector messes with the qt plugin). To run this notebook, set up the following environment:\n",
    "```\n",
    "conda create -n megadetector python=3.11 pip -y\n",
    "conda activate megadetector\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "pip3 install megadetector\n",
    "pip3 install pillow\n",
    "```\n",
    "The last section (5. Label!) in this notebook generates a command to be copy and pasted into a terminal. Before running this command in the terminal, set up a conda environment for labelme as follows: \n",
    "```\n",
    "git clone https://github.com/agentmorris/labelme\n",
    "cd labelme\n",
    "conda create -n labelme python=3.11 pip -y\n",
    "conda activate labelme\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "This notebook follows the following workflow:\n",
    "1. Downsize images to at most 1600px wide (assuming most camera trap images have a larger width than height) to improve the latency of labelme\n",
    "2. Running MDv5A on the dataset (adapted from https://github.com/agentmorris/MegaDetector/blob/main/notebooks/manage_local_batch.ipynb)\n",
    "3. Running RDE on the dataset (adapted from https://github.com/agentmorris/MegaDetector/blob/main/notebooks/manage_local_batch.ipynb)\n",
    "4. Prepare data for labelme \n",
    "    - Generate image folders each containing symlinks to 5k images as input to labelme to improve GUI latency (refer to https://github.com/yijint/Sentinel_Summer24/blob/main/reference_code/cxl-snapshot-relabeling.py emailed by Dan Morris \n",
    "    - Convert MD output for labelme compatability - this is an opinionated transformation that requires a confidence threshold (refer to https://github.com/agentmorris/MegaDetector/blob/main/megadetector/postprocessing/md_to_labelme.py)\n",
    "5. Label! (qt plugin required)\n",
    "    - If run into problems with initializing qt platform, try running `pip install pyside6`\n",
    "6. Labelme to MD: convert updated annotations into MD format \n",
    "\n",
    "All the package requirements are listed in `requirements.txt`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Set up"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import packages\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import stat\n",
    "import time\n",
    "import re\n",
    "from glob import glob\n",
    "import PIL\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import humanfriendly\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from megadetector.visualization.visualization_utils import resize_image_folder \n",
    "\n",
    "from megadetector.utils import path_utils\n",
    "from megadetector.utils.path_utils import find_image_strings\n",
    "from megadetector.utils.path_utils import recursive_file_list\n",
    "from megadetector.utils.path_utils import safe_create_link\n",
    "from megadetector.utils.ct_utils import split_list_into_n_chunks\n",
    "from megadetector.utils.ct_utils import image_file_to_camera_folder\n",
    "from megadetector.utils.ct_utils import split_list_into_fixed_size_chunks\n",
    "\n",
    "from megadetector.detection.run_detector_batch import load_and_run_detector_batch, write_results_to_file\n",
    "from megadetector.detection.run_detector import DEFAULT_OUTPUT_CONFIDENCE_THRESHOLD\n",
    "from megadetector.detection.run_detector import estimate_md_images_per_second\n",
    "from megadetector.detection.run_detector import get_detector_version_from_filename\n",
    "\n",
    "from megadetector.postprocessing.jin_md_to_labelme import md_to_labelme\n",
    "from megadetector.postprocessing.postprocess_batch_results import PostProcessingOptions, process_batch_results\n",
    "from megadetector.postprocessing.repeat_detection_elimination import repeat_detections_core\n",
    "from megadetector.postprocessing.repeat_detection_elimination import remove_repeat_detections"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# set paths and variables \n",
    "workdir = os.getcwd() # where this notebook and the original data lies, and where all the work will be done\n",
    "labelme_path = '/home/garage/Documents/jin-summer24/labelme' # where labelme was installed \n",
    "og_datapath = f\"{workdir}/data\" # where the original data is (just a subset of the NZ trailcam dataset for testing)\n",
    "metadata_path = f'{og_datapath}/trail_camera_images_of_new_zealand_animals_1.00.json' # metadata (for ALL data in the NZ trailcam dataset)\n",
    "datapath = f\"{workdir}/downsized_data\"\n",
    "first_run = False # some operations take a long time (MD detection, RDE, and most of all, generating multiple levels of labelme jsons). To avoid re-running these operations, set this to False after the first run. \n",
    "sort_all = True # whether to show images in datetime order in labelme"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# load metadata\n",
    "with open(metadata_path) as json_file:\n",
    "    metadata = json.load(json_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# retrieve unique image identifier from file path\n",
    "def get_file_id(fn):\n",
    "    return os.path.basename(fn).split('.')[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Downsize images to at most 1600px wide (assuming most camera trap images have a larger width than height) to improve the latency of labelme"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "if not os.path.exists(datapath):\n",
    "    os.mkdir(datapath)\n",
    "    # resize a folder of images to a new folder on multiple threads/processes.\n",
    "    %time _ = resize_image_folder(input_folder=og_datapath, output_folder=datapath, target_width=1600, target_height=-1, no_enlarge_width=True, verbose=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Running MDv5A on the dataset (adapted from https://github.com/agentmorris/MegaDetector/blob/main/notebooks/manage_local_batch.ipynb)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set constants"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "## Inference options\n",
    "\n",
    "# To specify a non-default confidence threshold for including detections in the .json file\n",
    "json_threshold = None\n",
    "\n",
    "# Turn warnings into errors if more than this many images are missing\n",
    "max_tolerable_failed_images = 100\n",
    "\n",
    "# Should we supply the --image_queue_option to run_detector_batch.py?  I only set this\n",
    "# when I have a very slow drive and a comparably fast GPU.  When this is enabled, checkpointing\n",
    "# is not supported within a job, so I set n_jobs to a large number (typically 100).\n",
    "use_image_queue = False\n",
    "\n",
    "# Only relevant when we're using a single GPU\n",
    "default_gpu_number = 0\n",
    "\n",
    "# Should we supply --quiet to run_detector_batch.py?\n",
    "quiet_mode = True\n",
    "\n",
    "# Specify a target image size when running MD... strongly recommended to leave this at \"None\"\n",
    "# When using augmented inference, if you leave this at \"None\", run_inference_with_yolov5_val.py\n",
    "# will use its default size, which is 1280 * 1.3, which is almost always what you want.\n",
    "image_size = None\n",
    "\n",
    "# Should we include image size, timestamp, and/or EXIF data in MD output?\n",
    "include_image_size = False\n",
    "include_image_timestamp = False\n",
    "include_exif_data = False\n",
    "\n",
    "# Only relevant when running on CPU\n",
    "ncores = 1\n",
    "\n",
    "# OS-specific script line continuation character (modified later if we're running on Windows)\n",
    "slcc = '\\\\'\n",
    "\n",
    "#  OS-specific script comment character (modified later if we're running on Windows)\n",
    "scc = '#'\n",
    "\n",
    "# # OS-specific script extension (modified later if we're running on Windows)\n",
    "script_extension = '.sh'\n",
    "\n",
    "# If False, we'll load chunk files with file lists if they exist\n",
    "force_enumeration = False\n",
    "\n",
    "# Prefer threads on Windows, processes on Linux\n",
    "parallelization_defaults_to_threads = False\n",
    "\n",
    "# This is for things like image rendering, not for MegaDetector\n",
    "default_workers_for_parallel_tasks = 30\n",
    "\n",
    "overwrite_handling = 'skip' # 'skip', 'error', or 'overwrite'\n",
    "\n",
    "# The function used to get camera names from image paths; can also replace this\n",
    "# with a custom function.\n",
    "relative_path_to_location = image_file_to_camera_folder\n",
    "\n",
    "# This will be the .json results file after RDE; if this is still None when\n",
    "# we get to classification stuff, that will indicate that we didn't do RDE.\n",
    "filtered_output_filename = None\n",
    "\n",
    "if os.name == 'nt':\n",
    "\n",
    "    slcc = '^'\n",
    "    scc = 'REM'\n",
    "    script_extension = '.bat'\n",
    "\n",
    "    # My experience has been that Python multiprocessing is flaky on Windows, so\n",
    "    # default to threads on Windows\n",
    "    parallelization_defaults_to_threads = True\n",
    "    default_workers_for_parallel_tasks = 10\n",
    "\n",
    "\n",
    "## Constants related to using YOLOv5's val.py\n",
    "\n",
    "# Should we use YOLOv5's val.py instead of run_detector_batch.py?\n",
    "use_yolo_inference_scripts = False\n",
    "\n",
    "# Directory in which to run val.py (relevant for YOLOv5, not for YOLOv8)\n",
    "yolo_working_dir = os.path.expanduser('~/git/yolov5')\n",
    "\n",
    "# Only used for loading the mapping from class indices to names\n",
    "yolo_dataset_file = None\n",
    "\n",
    "# 'yolov5' or 'yolov8'; assumes YOLOv5 if this is None\n",
    "yolo_model_type = None\n",
    "\n",
    "# inference batch size\n",
    "yolo_batch_size = 1\n",
    "\n",
    "# Should we remove intermediate files used for running YOLOv5's val.py?\n",
    "# Only relevant if use_yolo_inference_scripts is True.\n",
    "remove_yolo_intermediate_results = True\n",
    "remove_yolo_symlink_folder = True\n",
    "use_symlinks_for_yolo_inference = True\n",
    "write_yolo_debug_output = False\n",
    "\n",
    "# Should we apply YOLOv5's test-time augmentation?\n",
    "augment = False\n",
    "\n",
    "\n",
    "## Constants related to tiled inference\n",
    "\n",
    "use_tiled_inference = False\n",
    "\n",
    "# Should we delete tiles after each job?  Only set this to False for debugging;\n",
    "# large jobs will take up a lot of space if you keep tiles around after each task.\n",
    "remove_tiles = True\n",
    "tile_size = (1280,1280)\n",
    "tile_overlap = 0.2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Job-specific constants"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "input_path = datapath\n",
    "\n",
    "assert not (input_path.endswith('/') or input_path.endswith('\\\\'))\n",
    "assert os.path.isdir(input_path), 'Could not find input folder {}'.format(input_path)\n",
    "input_path = input_path.replace('\\\\','/')\n",
    "\n",
    "organization_name_short = 'nz-trailcams-aac-aiv'\n",
    "job_date = '2024-jun-07'\n",
    "assert job_date is not None and organization_name_short != 'organization'\n",
    "\n",
    "# Optional descriptor\n",
    "job_tag = None\n",
    "\n",
    "if job_tag is None:\n",
    "    job_description_string = ''\n",
    "else:\n",
    "    job_description_string = '-' + job_tag\n",
    "\n",
    "model_file = 'MDV5A' # 'MDV5A', 'MDV5B', 'MDV4'\n",
    "\n",
    "postprocessing_base = os.path.expanduser(f'{workdir}/postprocessing')\n",
    "\n",
    "# Number of jobs to split data into, typically equal to the number of available GPUs, though\n",
    "# when using augmentation or an image queue (and thus not using checkpoints), I typically\n",
    "# use ~100 jobs per GPU; those serve as de facto checkpoints.\n",
    "n_jobs = 1\n",
    "n_gpus = 1\n",
    "\n",
    "# Set to \"None\" when using augmentation or an image queue, which don't currently support\n",
    "# checkpointing.  Don't worry, this will be assert()'d in the next cell.\n",
    "checkpoint_frequency = 10000\n",
    "\n",
    "# Estimate inference speed for the current GPU\n",
    "approx_images_per_second = estimate_md_images_per_second(model_file)\n",
    "\n",
    "# Rough estimate for the inference time cost of augmentation\n",
    "if augment and (approx_images_per_second is not None):\n",
    "    approx_images_per_second = approx_images_per_second * 0.7\n",
    "\n",
    "base_task_name = organization_name_short + '-' + job_date + job_description_string + '-' + \\\n",
    "    get_detector_version_from_filename(model_file)\n",
    "base_output_folder_name = os.path.join(postprocessing_base,organization_name_short)\n",
    "os.makedirs(base_output_folder_name,exist_ok=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No speed estimate available for NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Derived variables, constant validation, path setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "if use_image_queue:\n",
    "    assert checkpoint_frequency is None,\\\n",
    "        'Checkpointing is not supported when using an image queue'\n",
    "\n",
    "if augment:\n",
    "    assert checkpoint_frequency is None,\\\n",
    "        'Checkpointing is not supported when using augmentation'\n",
    "\n",
    "    assert use_yolo_inference_scripts,\\\n",
    "        'Augmentation is only supported when running with the YOLO inference scripts'\n",
    "\n",
    "if use_tiled_inference:\n",
    "    assert not augment, \\\n",
    "        'Augmentation is not supported when using tiled inference'\n",
    "    assert not use_yolo_inference_scripts, \\\n",
    "        'Using the YOLO inference script is not supported when using tiled inference'\n",
    "    assert checkpoint_frequency is None, \\\n",
    "        'Checkpointing is not supported when using tiled inference'\n",
    "\n",
    "filename_base = os.path.join(base_output_folder_name, base_task_name)\n",
    "combined_api_output_folder = os.path.join(filename_base, 'combined_api_outputs')\n",
    "postprocessing_output_folder = os.path.join(filename_base, 'preview')\n",
    "\n",
    "combined_api_output_file = os.path.join(\n",
    "    combined_api_output_folder,\n",
    "    '{}_detections.json'.format(base_task_name))\n",
    "\n",
    "os.makedirs(filename_base, exist_ok=True)\n",
    "os.makedirs(combined_api_output_folder, exist_ok=True)\n",
    "os.makedirs(postprocessing_output_folder, exist_ok=True)\n",
    "\n",
    "if input_path.endswith('/'):\n",
    "    input_path = input_path[0:-1]\n",
    "\n",
    "print('Output folder:\\n{}'.format(filename_base))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Output folder:\n",
      "/home/garage/Documents/jin-summer24/Sentinel_Summer24/nz-trailcams-test/postprocessing/nz-trailcams-aac-aiv/nz-trailcams-aac-aiv-2024-jun-07-v5a.0.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Enumerate files (generate a list of image paths for future use)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "# Have we already listed files for this job?\n",
    "chunk_files = os.listdir(filename_base)\n",
    "pattern = re.compile('chunk\\d+.json')\n",
    "chunk_files = [fn for fn in chunk_files if pattern.match(fn)] # generated in cells below, if this does not exist\n",
    "\n",
    "if (not force_enumeration) and (len(chunk_files) > 0):\n",
    "\n",
    "    print('Found {} chunk files in folder {}, bypassing enumeration'.format(\n",
    "        len(chunk_files),\n",
    "        filename_base))\n",
    "\n",
    "    all_images = []\n",
    "    for fn in chunk_files:\n",
    "        with open(os.path.join(filename_base,fn),'r') as f:\n",
    "            chunk = json.load(f)\n",
    "            assert isinstance(chunk,list)\n",
    "            all_images.extend(chunk)\n",
    "    all_images = sorted(all_images)\n",
    "\n",
    "    print('Loaded {} image files from {} chunks in {}'.format(\n",
    "        len(all_images),len(chunk_files),filename_base))\n",
    "\n",
    "else:\n",
    "\n",
    "    print('Enumerating image files in {}'.format(input_path))\n",
    "\n",
    "    all_images = sorted(path_utils.find_images(input_path,recursive=True,convert_slashes=True))\n",
    "\n",
    "    # It's common to run this notebook on an external drive with the main folders in the drive root\n",
    "    all_images = [fn for fn in all_images if not \\\n",
    "                  (fn.startswith('$RECYCLE') or fn.startswith('System Volume Information'))]\n",
    "\n",
    "    print('')\n",
    "\n",
    "    print('Enumerated {} image files in {}'.format(len(all_images),input_path))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1 chunk files in folder /home/garage/Documents/jin-summer24/Sentinel_Summer24/nz-trailcams-test/postprocessing/nz-trailcams-aac-aiv/nz-trailcams-aac-aiv-2024-jun-07-v5a.0.0, bypassing enumeration\n",
      "Loaded 38 image files from 1 chunks in /home/garage/Documents/jin-summer24/Sentinel_Summer24/nz-trailcams-test/postprocessing/nz-trailcams-aac-aiv/nz-trailcams-aac-aiv-2024-jun-07-v5a.0.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Divide images into chunks for multiple processes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "folder_chunks = split_list_into_n_chunks(all_images,n_jobs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Estimate total time "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "if approx_images_per_second is None:\n",
    "\n",
    "    print(\"Can't estimate inference time for the current environment\")\n",
    "\n",
    "else:\n",
    "\n",
    "    n_images = len(all_images)\n",
    "    execution_seconds = n_images / approx_images_per_second\n",
    "    wallclock_seconds = execution_seconds / n_gpus\n",
    "    print('Expected time: {}'.format(humanfriendly.format_timespan(wallclock_seconds)))\n",
    "\n",
    "    seconds_per_chunk = len(folder_chunks[0]) / approx_images_per_second\n",
    "    print('Expected time per chunk: {}'.format(humanfriendly.format_timespan(seconds_per_chunk)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Can't estimate inference time for the current environment\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write file lists"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "task_info = []\n",
    "\n",
    "for i_chunk, chunk_list in enumerate(folder_chunks):\n",
    "\n",
    "    chunk_fn = os.path.join(filename_base,'chunk{}.json'.format(str(i_chunk).zfill(3)))\n",
    "    task_info.append({'id':i_chunk,'input_file':chunk_fn})\n",
    "    path_utils.write_list_to_file(chunk_fn, chunk_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate commands"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# A list of the scripts tied to each GPU, as absolute paths.  We'll write this out at\n",
    "# the end so each GPU's list of commands can be run at once\n",
    "gpu_to_scripts = defaultdict(list)\n",
    "\n",
    "# i_task = 0; task = task_info[i_task]\n",
    "for i_task,task in enumerate(task_info):\n",
    "\n",
    "    chunk_file = task['input_file']\n",
    "    checkpoint_filename = chunk_file.replace('.json','_checkpoint.json')\n",
    "\n",
    "    output_fn = chunk_file.replace('.json','_results.json')\n",
    "\n",
    "    task['output_file'] = output_fn\n",
    "\n",
    "    if n_gpus > 1:\n",
    "        gpu_number = i_task % n_gpus\n",
    "    else:\n",
    "        gpu_number = default_gpu_number\n",
    "\n",
    "    image_size_string = ''\n",
    "    if image_size is not None:\n",
    "        image_size_string = '--image_size {}'.format(image_size)\n",
    "\n",
    "    # Generate the script to run MD\n",
    "\n",
    "    if use_yolo_inference_scripts:\n",
    "\n",
    "        augment_string = ''\n",
    "        if augment:\n",
    "            augment_string = '--augment_enabled 1'\n",
    "        else:\n",
    "            augment_string = '--augment_enabled 0'\n",
    "\n",
    "        batch_string = '--batch_size {}'.format(yolo_batch_size)\n",
    "\n",
    "        symlink_folder = os.path.join(filename_base,'symlinks','symlinks_{}'.format(\n",
    "            str(i_task).zfill(3)))\n",
    "        yolo_results_folder = os.path.join(filename_base,'yolo_results','yolo_results_{}'.format(\n",
    "            str(i_task).zfill(3)))\n",
    "\n",
    "        symlink_folder_string = '--symlink_folder \"{}\"'.format(symlink_folder)\n",
    "        yolo_results_folder_string = '--yolo_results_folder \"{}\"'.format(yolo_results_folder)\n",
    "\n",
    "        remove_symlink_folder_string = ''\n",
    "        if not remove_yolo_symlink_folder:\n",
    "            remove_symlink_folder_string = '--no_remove_symlink_folder'\n",
    "\n",
    "        write_yolo_debug_output_string = ''\n",
    "        if write_yolo_debug_output:\n",
    "            write_yolo_debug_output = '--write_yolo_debug_output'\n",
    "\n",
    "        remove_yolo_results_string = ''\n",
    "        if not remove_yolo_intermediate_results:\n",
    "            remove_yolo_results_string = '--no_remove_yolo_results_folder'\n",
    "\n",
    "        confidence_threshold_string = ''\n",
    "        if json_threshold is not None:\n",
    "            confidence_threshold_string = '--conf_thres {}'.format(json_threshold)\n",
    "        else:\n",
    "            confidence_threshold_string = '--conf_thres {}'.format(DEFAULT_OUTPUT_CONFIDENCE_THRESHOLD)\n",
    "\n",
    "        cmd = ''\n",
    "\n",
    "        device_string = '--device {}'.format(gpu_number)\n",
    "\n",
    "        overwrite_handling_string = '--overwrite_handling {}'.format(overwrite_handling)\n",
    "\n",
    "        cmd += f'python run_inference_with_yolov5_val.py \"{model_file}\" \"{chunk_file}\" \"{output_fn}\" '\n",
    "        cmd += f'{image_size_string} {augment_string} '\n",
    "        cmd += f'{symlink_folder_string} {yolo_results_folder_string} {remove_yolo_results_string} '\n",
    "        cmd += f'{remove_symlink_folder_string} {confidence_threshold_string} {device_string} '\n",
    "        cmd += f'{overwrite_handling_string} {batch_string} {write_yolo_debug_output_string}'\n",
    "\n",
    "        if yolo_working_dir is not None:\n",
    "            cmd += f' --yolo_working_folder \"{yolo_working_dir}\"'\n",
    "        if yolo_dataset_file is not None:\n",
    "            cmd += ' --yolo_dataset_file \"{}\"'.format(yolo_dataset_file)\n",
    "        if yolo_model_type is not None:\n",
    "            cmd += ' --model_type {}'.format(yolo_model_type)\n",
    "\n",
    "        if not use_symlinks_for_yolo_inference:\n",
    "            cmd += ' --no_use_symlinks'\n",
    "\n",
    "        cmd += '\\n'\n",
    "\n",
    "    elif use_tiled_inference:\n",
    "\n",
    "        tiling_folder = os.path.join(filename_base,'tile_cache','tile_cache_{}'.format(\n",
    "            str(i_task).zfill(3)))\n",
    "\n",
    "        if os.name == 'nt':\n",
    "            cuda_string = f'set CUDA_VISIBLE_DEVICES={gpu_number} & '\n",
    "        else:\n",
    "            cuda_string = f'CUDA_VISIBLE_DEVICES={gpu_number} '\n",
    "\n",
    "        cmd = f'{cuda_string} python run_tiled_inference.py \"{model_file}\" \"{input_path}\" \"{tiling_folder}\" \"{output_fn}\"'\n",
    "\n",
    "        cmd += f' --image_list \"{chunk_file}\"'\n",
    "        cmd += f' --overwrite_handling {overwrite_handling}'\n",
    "\n",
    "        if not remove_tiles:\n",
    "            cmd += ' --no_remove_tiles'\n",
    "\n",
    "        # If we're using non-default tile sizes\n",
    "        if tile_size is not None and (tile_size[0] > 0 or tile_size[1] > 0):\n",
    "            cmd += ' --tile_size_x {} --tile_size_y {}'.format(tile_size[0],tile_size[1])\n",
    "\n",
    "        if tile_overlap is not None:\n",
    "            cmd += f' --tile_overlap {tile_overlap}'\n",
    "\n",
    "    else:\n",
    "\n",
    "        if os.name == 'nt':\n",
    "            cuda_string = f'set CUDA_VISIBLE_DEVICES={gpu_number} & '\n",
    "        else:\n",
    "            cuda_string = f'CUDA_VISIBLE_DEVICES={gpu_number} '\n",
    "\n",
    "        checkpoint_frequency_string = ''\n",
    "        checkpoint_path_string = ''\n",
    "\n",
    "        if checkpoint_frequency is not None and checkpoint_frequency > 0:\n",
    "            checkpoint_frequency_string = f'--checkpoint_frequency {checkpoint_frequency}'\n",
    "            checkpoint_path_string = '--checkpoint_path \"{}\"'.format(checkpoint_filename)\n",
    "\n",
    "        use_image_queue_string = ''\n",
    "        if (use_image_queue):\n",
    "            use_image_queue_string = '--use_image_queue'\n",
    "\n",
    "        ncores_string = ''\n",
    "        if (ncores > 1):\n",
    "            ncores_string = '--ncores {}'.format(ncores)\n",
    "\n",
    "        quiet_string = ''\n",
    "        if quiet_mode:\n",
    "            quiet_string = '--quiet'\n",
    "\n",
    "        confidence_threshold_string = ''\n",
    "        if json_threshold is not None:\n",
    "            confidence_threshold_string = '--threshold {}'.format(json_threshold)\n",
    "\n",
    "        overwrite_handling_string = '--overwrite_handling {}'.format(overwrite_handling)\n",
    "        cmd = f'{cuda_string} python run_detector_batch.py \"{model_file}\" \"{chunk_file}\" \"{output_fn}\" {checkpoint_frequency_string} {checkpoint_path_string} {use_image_queue_string} {ncores_string} {quiet_string} {image_size_string} {confidence_threshold_string} {overwrite_handling_string}'\n",
    "\n",
    "        if include_image_size:\n",
    "            cmd += ' --include_image_size'\n",
    "        if include_image_timestamp:\n",
    "            cmd += ' --include_image_timestamp'\n",
    "        if include_exif_data:\n",
    "            cmd += ' --include_exif_data'\n",
    "\n",
    "    cmd_file = os.path.join(filename_base,'run_chunk_{}_gpu_{}{}'.format(str(i_task).zfill(3),\n",
    "                            str(gpu_number).zfill(2),script_extension))\n",
    "\n",
    "    with open(cmd_file,'w') as f:\n",
    "        f.write(cmd + '\\n')\n",
    "\n",
    "    st = os.stat(cmd_file)\n",
    "    os.chmod(cmd_file, st.st_mode | stat.S_IEXEC)\n",
    "\n",
    "    task['command'] = cmd\n",
    "    task['command_file'] = cmd_file\n",
    "\n",
    "    # Generate the script to resume from the checkpoint (only supported with MD inference code)\n",
    "\n",
    "    gpu_to_scripts[gpu_number].append(cmd_file)\n",
    "\n",
    "    if checkpoint_frequency is not None:\n",
    "\n",
    "        resume_string = ' --resume_from_checkpoint \"{}\"'.format(checkpoint_filename)\n",
    "        resume_cmd = cmd + resume_string\n",
    "\n",
    "        resume_cmd_file = os.path.join(filename_base,\n",
    "                                       'resume_chunk_{}_gpu_{}{}'.format(str(i_task).zfill(3),\n",
    "                                       str(gpu_number).zfill(2),script_extension))\n",
    "\n",
    "        with open(resume_cmd_file,'w') as f:\n",
    "            f.write(resume_cmd + '\\n')\n",
    "\n",
    "        st = os.stat(resume_cmd_file)\n",
    "        os.chmod(resume_cmd_file, st.st_mode | stat.S_IEXEC)\n",
    "\n",
    "        task['resume_command'] = resume_cmd\n",
    "        task['resume_command_file'] = resume_cmd_file\n",
    "\n",
    "# ...for each task\n",
    "\n",
    "# Write out a script for each GPU that runs all of the commands associated with\n",
    "# that GPU.  Typically only used when running lots of little scripts in lieu\n",
    "# of checkpointing.\n",
    "for gpu_number in gpu_to_scripts:\n",
    "\n",
    "    gpu_script_file = os.path.join(filename_base,'run_all_for_gpu_{}{}'.format(\n",
    "        str(gpu_number).zfill(2),script_extension))\n",
    "    with open(gpu_script_file,'w') as f:\n",
    "        for script_name in gpu_to_scripts[gpu_number]:\n",
    "            s = script_name\n",
    "            # When calling a series of batch files on Windows from within a batch file, you need to\n",
    "            # use \"call\", or only the first will be executed.  No, it doesn't make sense.\n",
    "            if os.name == 'nt':\n",
    "                s = 'call ' + s\n",
    "            f.write(s + '\\n')\n",
    "        f.write('echo \"Finished all commands for GPU {}\"'.format(gpu_number))\n",
    "    st = os.stat(gpu_script_file)\n",
    "    os.chmod(gpu_script_file, st.st_mode | stat.S_IEXEC)\n",
    "\n",
    "# ...for each GPU"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the tasks\n",
    "\n",
    "The cells we've run so far wrote out some shell scripts (.bat files on Windows,\n",
    ".sh files on Linx/Mac) that will run MegaDetector.  I like to leave the interactive\n",
    "environment at this point and run those scripts at the command line.  So, for example,\n",
    "if you're on Windows, and you've basically used the default values above, there will be\n",
    "batch files called, e.g.:\n",
    "\n",
    "c:\\users\\[username]\\postprocessing\\[organization]\\[job_name]\\run_chunk_000_gpu_00.bat\n",
    "c:\\users\\[username]\\postprocessing\\[organization]\\[job_name]\\run_chunk_001_gpu_01.bat\n",
    "\n",
    "Those batch files expect to be run from the \"detection\" folder of the MegaDetector repo,\n",
    "typically:\n",
    "\n",
    "c:\\git\\MegaDetector\\megadetector\\detection\n",
    "\n",
    "All of that said, you don't *have* to do this at the command line.  The following cell\n",
    "runs these scripts programmatically, so if you set \"run_tasks_in_notebook\" to \"True\"\n",
    "and run this cell, you can run MegaDetector without leaving this notebook.\n",
    "\n",
    "One downside of the programmatic approach is that this cell doesn't yet parallelize over\n",
    "multiple processes, so the tasks will run serially.  This only matters if you have\n",
    "multiple GPUs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "run_tasks_in_notebook = True\n",
    "\n",
    "if run_tasks_in_notebook and first_run:\n",
    "\n",
    "    assert not use_yolo_inference_scripts, \\\n",
    "        'If you want to use the YOLOv5 inference scripts, you can\\'t run the model interactively (yet)'\n",
    "\n",
    "    # i_task = 0; task = task_info[i_task]\n",
    "    for i_task,task in enumerate(task_info):\n",
    "\n",
    "        chunk_file = task['input_file']\n",
    "        output_fn = task['output_file']\n",
    "\n",
    "        checkpoint_filename = chunk_file.replace('.json','_checkpoint.json')\n",
    "\n",
    "        if json_threshold is not None:\n",
    "            confidence_threshold = json_threshold\n",
    "        else:\n",
    "            confidence_threshold = DEFAULT_OUTPUT_CONFIDENCE_THRESHOLD\n",
    "\n",
    "        if checkpoint_frequency is not None and checkpoint_frequency > 0:\n",
    "            cp_freq_arg = checkpoint_frequency\n",
    "        else:\n",
    "            cp_freq_arg = -1\n",
    "\n",
    "        start_time = time.time()\n",
    "        results = load_and_run_detector_batch(model_file=model_file,\n",
    "                                              image_file_names=chunk_file,\n",
    "                                              checkpoint_path=checkpoint_filename,\n",
    "                                              confidence_threshold=confidence_threshold,\n",
    "                                              checkpoint_frequency=cp_freq_arg,\n",
    "                                              results=None,\n",
    "                                              n_cores=ncores,\n",
    "                                              use_image_queue=use_image_queue,\n",
    "                                              quiet=quiet_mode,\n",
    "                                              image_size=image_size)\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        print('Task {}: finished inference for {} images in {}'.format(\n",
    "            i_task, len(results),humanfriendly.format_timespan(elapsed)))\n",
    "\n",
    "        # This will write absolute paths to the file, we'll fix this later\n",
    "        write_results_to_file(results, output_fn, detector_file=model_file)\n",
    "\n",
    "        if checkpoint_frequency is not None and checkpoint_frequency > 0:\n",
    "            if os.path.isfile(checkpoint_filename):\n",
    "                os.remove(checkpoint_filename)\n",
    "                print('Deleted checkpoint file {}'.format(checkpoint_filename))\n",
    "\n",
    "    # ...for each chunk\n",
    "\n",
    "# ...if we're running tasks in this notebook"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load results, look for failed or missing images in each task"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "# Check that all task output files exist\n",
    "\n",
    "if first_run:\n",
    "    missing_output_files = []\n",
    "\n",
    "    # i_task = 0; task = task_info[i_task]\n",
    "    for i_task, task in tqdm(enumerate(task_info),total=len(task_info)):\n",
    "        output_file = task['output_file']\n",
    "        if not os.path.isfile(output_file):\n",
    "            missing_output_files.append(output_file)\n",
    "\n",
    "    if len(missing_output_files) > 0:\n",
    "        print('Missing {} output files:'.format(len(missing_output_files)))\n",
    "        for s in missing_output_files:\n",
    "            print(s)\n",
    "        raise Exception('Missing output files')\n",
    "\n",
    "\n",
    "    n_total_failures = 0\n",
    "\n",
    "    for i_task,task in tqdm(enumerate(task_info),total=len(task_info)):\n",
    "\n",
    "        chunk_file = task['input_file']\n",
    "        output_file = task['output_file']\n",
    "\n",
    "        with open(chunk_file,'r') as f:\n",
    "            task_images = json.load(f)\n",
    "        with open(output_file,'r') as f:\n",
    "            task_results = json.load(f)\n",
    "\n",
    "        task_images_set = set(task_images)\n",
    "        filename_to_results = {}\n",
    "\n",
    "        n_task_failures = 0\n",
    "\n",
    "        for im in task_results['images']:\n",
    "\n",
    "            # Most of the time, inference result files use absolute paths, but it's\n",
    "            # getting annoying to make sure that's *always* true, so handle both here.\n",
    "            # E.g., when using tiled inference, paths will be relative.\n",
    "            if not os.path.isabs(im['file']):\n",
    "                fn = os.path.join(input_path,im['file']).replace('\\\\','/')\n",
    "                im['file'] = fn\n",
    "            assert im['file'].startswith(input_path)\n",
    "            assert im['file'] in task_images_set\n",
    "            filename_to_results[im['file']] = im\n",
    "            if 'failure' in im:\n",
    "                assert im['failure'] is not None\n",
    "                n_task_failures += 1\n",
    "\n",
    "        task['n_failures'] = n_task_failures\n",
    "        task['results'] = task_results\n",
    "\n",
    "        for fn in task_images:\n",
    "            assert fn in filename_to_results, \\\n",
    "                'File {} not found in results for task {}'.format(fn,i_task)\n",
    "\n",
    "        n_total_failures += n_task_failures\n",
    "\n",
    "    # ...for each task\n",
    "\n",
    "    assert n_total_failures < max_tolerable_failed_images,\\\n",
    "        '{} failures (max tolerable set to {})'.format(n_total_failures,\n",
    "                                                    max_tolerable_failed_images)\n",
    "\n",
    "    print('Processed all {} images with {} failures'.format(\n",
    "        len(all_images),n_total_failures))\n",
    "\n",
    "\n",
    "    ##%% Merge results files and make filenames relative\n",
    "\n",
    "    combined_results = {}\n",
    "    combined_results['images'] = []\n",
    "    images_processed = set()\n",
    "\n",
    "    for i_task,task in tqdm(enumerate(task_info),total=len(task_info)):\n",
    "\n",
    "        task_results = task['results']\n",
    "\n",
    "        if i_task == 0:\n",
    "            combined_results['info'] = task_results['info']\n",
    "            combined_results['detection_categories'] = task_results['detection_categories']\n",
    "        else:\n",
    "            assert task_results['info']['format_version'] == combined_results['info']['format_version']\n",
    "            assert task_results['detection_categories'] == combined_results['detection_categories']\n",
    "\n",
    "        # Make sure we didn't see this image in another chunk\n",
    "        for im in task_results['images']:\n",
    "            assert im['file'] not in images_processed\n",
    "            images_processed.add(im['file'])\n",
    "\n",
    "        combined_results['images'].extend(task_results['images'])\n",
    "\n",
    "    # Check that we ended up with the right number of images\n",
    "    assert len(combined_results['images']) == len(all_images), \\\n",
    "        'Expected {} images in combined results, found {}'.format(\n",
    "            len(all_images),len(combined_results['images']))\n",
    "\n",
    "    # Check uniqueness\n",
    "    result_filenames = [im['file'] for im in combined_results['images']]\n",
    "    assert len(combined_results['images']) == len(set(result_filenames))\n",
    "\n",
    "    # Convert to relative paths, preserving '/' as the path separator, regardless of OS\n",
    "    for im in combined_results['images']:\n",
    "        assert '\\\\' not in im['file']\n",
    "        assert im['file'].startswith(input_path)\n",
    "        if input_path.endswith(':'):\n",
    "            im['file'] = im['file'].replace(input_path,'',1)\n",
    "        else:\n",
    "            im['file'] = im['file'].replace(input_path + '/','',1)\n",
    "\n",
    "    with open(combined_api_output_file,'w') as f:\n",
    "        json.dump(combined_results,f,indent=1)\n",
    "\n",
    "    print('Wrote results to {}'.format(combined_api_output_file))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Post-processing (pre-RDE)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "render_animals_only = False\n",
    "\n",
    "options = PostProcessingOptions()\n",
    "options.image_base_dir = input_path\n",
    "options.include_almost_detections = True\n",
    "options.num_images_to_sample = 7500\n",
    "options.confidence_threshold = 0.2\n",
    "options.almost_detection_confidence_threshold = options.confidence_threshold - 0.05\n",
    "options.ground_truth_json_file = None\n",
    "options.separate_detections_by_category = True\n",
    "options.sample_seed = 0\n",
    "options.max_figures_per_html_file = 2500\n",
    "\n",
    "options.parallelize_rendering = True\n",
    "options.parallelize_rendering_n_cores = default_workers_for_parallel_tasks\n",
    "options.parallelize_rendering_with_threads = parallelization_defaults_to_threads\n",
    "\n",
    "if render_animals_only:\n",
    "    # Omit some pages from the output, useful when animals are rare\n",
    "    options.rendering_bypass_sets = ['detections_person','detections_vehicle',\n",
    "                                     'detections_person_vehicle','non_detections']\n",
    "\n",
    "output_base = os.path.join(postprocessing_output_folder,\n",
    "    base_task_name + '_{:.3f}'.format(options.confidence_threshold))\n",
    "if render_animals_only:\n",
    "    output_base = output_base + '_animals_only'\n",
    "\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "print('Processing to {}'.format(output_base))\n",
    "\n",
    "options.md_results_file = combined_api_output_file\n",
    "options.output_dir = output_base\n",
    "\n",
    "if first_run:\n",
    "    ppresults = process_batch_results(options)\n",
    "    html_output_file = ppresults.output_html_file\n",
    "    path_utils.open_file(html_output_file,attempt_to_open_in_wsl_host=True,browser_name='chrome')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing to /home/garage/Documents/jin-summer24/Sentinel_Summer24/nz-trailcams-test/postprocessing/nz-trailcams-aac-aiv/nz-trailcams-aac-aiv-2024-jun-07-v5a.0.0/preview/nz-trailcams-aac-aiv-2024-jun-07-v5a.0.0_0.200\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Running RDE on the dataset (adapted from https://github.com/agentmorris/MegaDetector/blob/main/notebooks/manage_local_batch.ipynb)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Repeat detection elimination (RDE)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "task_index = 0\n",
    "\n",
    "options = repeat_detections_core.RepeatDetectionOptions()\n",
    "\n",
    "options.confidenceMin = 0.1\n",
    "options.confidenceMax = 1.01\n",
    "options.iouThreshold = 0.85\n",
    "options.occurrenceThreshold = 15\n",
    "options.maxSuspiciousDetectionSize = 0.2\n",
    "# options.minSuspiciousDetectionSize = 0.05\n",
    "\n",
    "options.parallelizationUsesThreads = parallelization_defaults_to_threads\n",
    "options.nWorkers = default_workers_for_parallel_tasks\n",
    "\n",
    "# This will cause a very light gray box to get drawn around all the detections\n",
    "# we're *not* considering as suspicious.\n",
    "options.bRenderOtherDetections = True\n",
    "options.otherDetectionsThreshold = options.confidenceMin\n",
    "\n",
    "options.bRenderDetectionTiles = True\n",
    "options.maxOutputImageWidth = 2000\n",
    "options.detectionTilesMaxCrops = 250\n",
    "\n",
    "# options.lineThickness = 5\n",
    "# options.boxExpansion = 8\n",
    "\n",
    "# To invoke custom collapsing of folders for a particular manufacturer's naming scheme\n",
    "options.customDirNameFunction = relative_path_to_location\n",
    "\n",
    "options.bRenderHtml = False\n",
    "options.imageBase = input_path\n",
    "rde_string = 'rde_{:.3f}_{:.3f}_{}_{:.3f}'.format(\n",
    "    options.confidenceMin, options.iouThreshold,\n",
    "    options.occurrenceThreshold, options.maxSuspiciousDetectionSize)\n",
    "options.outputBase = os.path.join(filename_base, rde_string + '_task_{}'.format(task_index))\n",
    "options.filenameReplacements = None # {'':''}\n",
    "\n",
    "# Exclude people and vehicles from RDE\n",
    "# options.excludeClasses = [2,3]\n",
    "\n",
    "# options.maxImagesPerFolder = 50000\n",
    "# options.includeFolders = ['a/b/c']\n",
    "# options.excludeFolder = ['a/b/c']\n",
    "\n",
    "options.debugMaxDir = -1\n",
    "options.debugMaxRenderDir = -1\n",
    "options.debugMaxRenderDetection = -1\n",
    "options.debugMaxRenderInstance = -1\n",
    "\n",
    "# Can be None, 'xsort', or 'clustersort'\n",
    "options.smartSort = 'xsort'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "if first_run:\n",
    "    %time suspicious_detection_results = repeat_detections_core.find_repeat_detections(combined_api_output_file, outputFilename=None, options=options)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Manual RDE step (deleting the valid detections from the suspicious detections)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "## DELETE THE VALID DETECTIONS ##\n",
    "\n",
    "# If you run this line, it will open the folder up in your file browser\n",
    "if first_run:\n",
    "    path_utils.open_file(os.path.dirname(suspicious_detection_results.filterFile),\n",
    "                        attempt_to_open_in_wsl_host=True)\n",
    "\n",
    "# If you ran the previous cell, but then you change your mind and you don't want to do\n",
    "# the RDE step, that's fine, but don't just blast through this cell once you've run the\n",
    "# previous cell.  If you do that, you're implicitly telling the notebook that you looked\n",
    "# at everything in that folder, and confirmed there were no red boxes on animals.\n",
    "\n",
    "# Instead, either change \"filtered_output_filename\" below to \"combined_api_output_file\",\n",
    "# or delete *all* the images in the filtering folder."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Re-filtering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "filtered_output_filename = path_utils.insert_before_extension(combined_api_output_file,\n",
    "                                                              'filtered_{}'.format(rde_string))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "if first_run:\n",
    "    remove_repeat_detections.remove_repeat_detections(\n",
    "        inputFile=combined_api_output_file,\n",
    "        outputFile=filtered_output_filename,\n",
    "        filteringDir=os.path.dirname(suspicious_detection_results.filterFile)\n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Post-processing (post-RDE)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "render_animals_only = False\n",
    "\n",
    "options = PostProcessingOptions()\n",
    "options.image_base_dir = input_path\n",
    "options.include_almost_detections = True\n",
    "options.num_images_to_sample = 7500\n",
    "options.confidence_threshold = 0.2\n",
    "options.almost_detection_confidence_threshold = options.confidence_threshold - 0.05\n",
    "options.ground_truth_json_file = None\n",
    "options.separate_detections_by_category = True\n",
    "options.sample_seed = 0\n",
    "options.max_figures_per_html_file = 5000\n",
    "\n",
    "options.parallelize_rendering = True\n",
    "options.parallelize_rendering_n_cores = default_workers_for_parallel_tasks\n",
    "options.parallelize_rendering_with_threads = parallelization_defaults_to_threads\n",
    "\n",
    "if render_animals_only:\n",
    "    # Omit some pages from the output, useful when animals are rare\n",
    "    options.rendering_bypass_sets = ['detections_person','detections_vehicle',\n",
    "                                      'detections_person_vehicle','non_detections']\n",
    "\n",
    "output_base = os.path.join(postprocessing_output_folder,\n",
    "    base_task_name + '_{}_{:.3f}'.format(rde_string, options.confidence_threshold))\n",
    "\n",
    "if render_animals_only:\n",
    "    output_base = output_base + '_render_animals_only'\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "print('Processing post-RDE to {}'.format(output_base))\n",
    "\n",
    "options.md_results_file = filtered_output_filename\n",
    "options.output_dir = output_base\n",
    "\n",
    "if first_run:\n",
    "    ppresults = process_batch_results(options)\n",
    "    html_output_file = ppresults.output_html_file\n",
    "    path_utils.open_file(html_output_file,attempt_to_open_in_wsl_host=True,browser_name='chrome')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing post-RDE to /home/garage/Documents/jin-summer24/Sentinel_Summer24/nz-trailcams-test/postprocessing/nz-trailcams-aac-aiv/nz-trailcams-aac-aiv-2024-jun-07-v5a.0.0/preview/nz-trailcams-aac-aiv-2024-jun-07-v5a.0.0_rde_0.100_0.850_15_0.200_0.200\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Prepare data for labelme"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "md_results_file = filtered_output_filename \n",
    "relabeling_folder_base = datapath\n",
    "symlink_folder = f'{workdir}/relabeling-symlinks'\n",
    "\n",
    "# Ensure that paths are normalized\n",
    "md_results_file = md_results_file.replace('\\\\','/')\n",
    "relabeling_folder_base = relabeling_folder_base.replace('\\\\','/')\n",
    "symlink_folder = symlink_folder.replace('\\\\','/')\n",
    "use_threads = True\n",
    "n_workers = 10\n",
    "\n",
    "batch_name = 'nz-trailcams-acc-aiv'\n",
    "max_images_per_chunk = 5000\n",
    "\n",
    "assert os.path.isfile(md_results_file)\n",
    "assert os.path.isdir(relabeling_folder_base)\n",
    "os.makedirs(symlink_folder,exist_ok=True)\n",
    "\n",
    "default_confidence_threshold = 0.2\n",
    "\n",
    "# This defines the set of backup label files we generate from MD results at lower confidence thresholds\n",
    "index_to_threshold = {\n",
    "    1:0.1,\n",
    "    2:0.05,\n",
    "    3:0.01\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert MD results to labelme format with a default threshold\n",
    "if first_run:\n",
    "    _ = md_to_labelme(results_file=md_results_file,\n",
    "                    image_base=relabeling_folder_base,\n",
    "                    confidence_threshold=default_confidence_threshold,\n",
    "                    overwrite=True,\n",
    "                    extension_prefix='',\n",
    "                    n_workers=n_workers,\n",
    "                    use_threads=use_threads,\n",
    "                    bypass_image_size_read=False,\n",
    "                    verbose=True)\n",
    "\n",
    "    # Create alternative .json files based on MD results at lower thresholds\n",
    "\n",
    "    for index in index_to_threshold.keys():\n",
    "        \n",
    "        print('Generating alternative labels for index {} (threshold {})'.format(\n",
    "            index,index_to_threshold[index]))\n",
    "        \n",
    "        md_to_labelme(results_file=md_results_file,\n",
    "                    image_base=relabeling_folder_base,\n",
    "                    confidence_threshold=index_to_threshold[index],\n",
    "                    overwrite=True,\n",
    "                    use_threads=use_threads,\n",
    "                    bypass_image_size_read=False,\n",
    "                    extension_prefix='.alt-{}'.format(index),\n",
    "                    n_workers=n_workers)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Enumerate files\n",
    "\n",
    "all_files_relative = recursive_file_list(relabeling_folder_base,\n",
    "                                         return_relative_paths=True,\n",
    "                                         convert_slashes=True,\n",
    "                                         recursive=True)\n",
    "\n",
    "print('Enumerated {} files'.format(len(all_files_relative)))\n",
    "\n",
    "\n",
    "# Match .json files to images\n",
    "image_files_relative = find_image_strings(all_files_relative)\n",
    "image_files_relative = [fp for fp in image_files_relative if 'symlinks' not in fp]\n",
    "json_files = [fn for fn in all_files_relative if fn.endswith('.json') and 'symlinks' not in fn]\n",
    "json_files = sorted(json_files)\n",
    "\n",
    "print('Enumerated {} image files and {} .json files'.format(\n",
    "    len(image_files_relative),len(json_files)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Enumerated 384 files\n",
      "Enumerated 38 image files and 152 .json files\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sort images by metadata"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "source": [
    "# load image metadata\n",
    "images_df = pd.DataFrame(metadata['images'])[['location','datetime','file_name','species']]\n",
    "\n",
    "# retrieve unique image identifier from metadata \n",
    "%time images_df['uuid'] = images_df.apply(lambda x: get_file_id(x.file_name), 1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 17.6 s, sys: 134 ms, total: 17.7 s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "source": [
    "# gather all image file paths we care about and retrieve their unique image identifier \n",
    "image_extensions = [\n",
    "    '**/*.png', '**/*.PNG', '**/*.jpg', '**/*.JPG', '**/*.jpeg', '**/*.JPEG',\n",
    "    '**/*.gif', '**/*.GIF', '**/*.bmp', '**/*.BMP', '**/*.tiff', '**/*.TIFF',\n",
    "    '**/*.webp', '**/*.WEBP'\n",
    "]\n",
    "image_files = []\n",
    "for ext in image_extensions:\n",
    "    image_files.extend(glob(f\"{datapath}/{ext}\", recursive=True))\n",
    "image_files = list(map(get_file_id, image_files))\n",
    "\n",
    "# filter metadata to only contain images we care about\n",
    "include_image = [True if image_id in image_files else False for image_id in images_df.uuid]\n",
    "images_df = images_df.loc[include_image].reset_index(drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "# covert datetime string into datetime object, and extract the value from EXIF data where necessary \n",
    "if sort_all:\n",
    "    EXIF_extracted = 0\n",
    "\n",
    "    tic = time.time()\n",
    "    for row_idx, dt in enumerate(images_df['datetime']):\n",
    "        if type(dt) == type(None): # If datetime is not available, extract from EXIF data.\n",
    "            EXIF_extracted += 1 \n",
    "            DT_TAG = 306 # tag number for DateTime in exif object \n",
    "            NZ_EXIF_DT_FORMAT = \"%Y:%m:%d %H:%M:%S\"\n",
    "            exif_dt = PIL.Image.open(f'{datapath}/{images_df[\"file_name\"][row_idx]}')._getexif()[DT_TAG]\n",
    "            images_df['datetime'].iloc[row_idx]= datetime.strptime(exif_dt, NZ_EXIF_DT_FORMAT)\n",
    "        else: \n",
    "            MD_DT_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n",
    "            images_df['datetime'].iloc[row_idx] = datetime.strptime(dt, MD_DT_FORMAT)\n",
    "    toc = time.time()\n",
    "    print(f\"Time taken to retrieve all locations, datetime, and species for {len(location.keys())} images from metadata and extract EXIF data for {EXIF_extracted} images: {(toc-tic)} seconds\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time taken to retrieve all locations, datetime, and species for 38 images from metadata and extract EXIF data for 0 images: 0.005779266357421875 seconds\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if sort_all:\n",
    "    # find the rank of each image sorted by location, species, and datetime\n",
    "    loc_index_map = {val : idx for idx, val in enumerate(sorted(images_df['location']))}\n",
    "    spec_index_map = {val : idx for idx, val in enumerate(sorted(images_df['species']))}\n",
    "    dt_index_map = {val : idx for idx, val in enumerate(sorted(images_df['datetime']))}\n",
    "\n",
    "    images_df['location_rank'] = images_df.apply(lambda x: loc_index_map[x.location], 1)\n",
    "    images_df['species_rank'] = images_df.apply(lambda x: spec_index_map[x.species], 1)\n",
    "    images_df['datetime_rank'] = images_df.apply(lambda x: dt_index_map[x.datetime], 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Group json files by the image they belong to\n",
    "\n",
    "# We'll use this to create symlinks to every file that goes with each image in\n",
    "# a chunk.\n",
    "\n",
    "image_file_base_to_json_files = defaultdict(list)\n",
    "\n",
    "for json_file in tqdm(json_files):\n",
    "\n",
    "    file_id = get_file_id(json_file)\n",
    "    image_file_base_to_json_files[file_id].append(json_file)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|| 152/152 [00:00<00:00, 398210.00it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Make sure every image has the right number of .json files\n",
    "\n",
    "unlabeled_image_files = []\n",
    "\n",
    "for image_file in tqdm(image_files_relative):    \n",
    "    basename = get_file_id(image_file)\n",
    "    json_files_this_image = image_file_base_to_json_files[basename]\n",
    "    assert len(json_files_this_image) == 4\n",
    "    if len(json_files_this_image) == 0:\n",
    "        unlabeled_image_files.append(image_file)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|| 38/38 [00:00<00:00, 226075.96it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Divide into chunks, create symlinks\n",
    "\n",
    "chunks = split_list_into_fixed_size_chunks(image_files_relative,max_images_per_chunk)\n",
    "\n",
    "print('Split images into {} chunks of {} images'.format(len(chunks),max_images_per_chunk))\n",
    "\n",
    "chunk_folder_base = os.path.join(relabeling_folder_base,'symlinks-{}'.format(batch_name))\n",
    "chunk_folders = []\n",
    "error_files = []\n",
    "\n",
    "for i_chunk,chunk in enumerate(chunks):\n",
    "    \n",
    "    print('Creating symlinks for chunk {} of {}'.format(i_chunk,len(chunks)))\n",
    "\n",
    "    chunk_folder_abs = os.path.join(chunk_folder_base,'chunk_{}'.format(\n",
    "        str(i_chunk).zfill(3)))\n",
    "    os.makedirs(chunk_folder_abs,exist_ok=True)\n",
    "    chunk_folders.append(chunk_folder_abs)\n",
    "    \n",
    "    # Find matching files\n",
    "    relative_files_this_chunk = []\n",
    "    \n",
    "    for i_image,image_file in enumerate(chunk):\n",
    "        \n",
    "        # image_file_abs = os.path.join(training_images_resized_folder,image_file); open_file(image_file_abs)\n",
    "        basename = get_file_id(image_file)\n",
    "        json_files_this_image = image_file_base_to_json_files[basename]\n",
    "        \n",
    "        # These are typically images that failed to load\n",
    "        if len(json_files_this_image) == 0:\n",
    "            print('Warning: no .json files for {}'.format(image_file))\n",
    "            error_files.append(image_file)\n",
    "            continue\n",
    "        \n",
    "        assert len(json_files_this_image) > 0\n",
    "        relative_files_this_chunk.append(image_file)\n",
    "        \n",
    "        for json_file in json_files_this_image:\n",
    "            relative_files_this_chunk.append(json_file)          \n",
    "\n",
    "    # Create symlinks\n",
    "    for relative_file in tqdm(relative_files_this_chunk):\n",
    "        source_file_abs = os.path.join(relabeling_folder_base,relative_file)\n",
    "        assert os.path.isfile(source_file_abs)\n",
    "        target_file_abs = os.path.join(chunk_folder_abs,relative_file)\n",
    "\n",
    "        # sorting location, species, and datetime based on metadata, not relying on folder hierarchy\n",
    "        if sort_all:\n",
    "            file_id = get_file_id(relative_file)\n",
    "            loc_order = images_df[images_df.uuid == file_id].location_rank.item()\n",
    "            spec_order = images_df[images_df.uuid == file_id].species_rank.item()\n",
    "            dt_order = images_df[images_df.uuid == file_id].datetime_rank.item()\n",
    "            relative_file_pieces = relative_file.split(\"/\")\n",
    "            relative_file_base = \"/\".join(relative_file_pieces[:-1])\n",
    "            relative_file_name = relative_file_pieces[-1]\n",
    "            target_file_abs = f\"{chunk_folder_abs}/loc-{loc_order}/spec-{spec_order}/dt-{dt_order}/{relative_file_name}\"\n",
    "\n",
    "        os.makedirs(os.path.dirname(target_file_abs),exist_ok=True)\n",
    "        safe_create_link(source_file_abs,target_file_abs)\n",
    "\n",
    "# ...for each chunk\n",
    "\n",
    "error_file_list_file = os.path.join(chunk_folder_base,'error_images.json')\n",
    "print('\\nSaving list of {} error images to {}'.format(len(error_files),error_file_list_file))\n",
    "with open(error_file_list_file,'w') as f:\n",
    "    json.dump(error_files,f,indent=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Split images into 1 chunks of 5000 images\n",
      "Creating symlinks for chunk 0 of 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|| 190/190 [00:00<00:00, 39606.27it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Saving list of 0 error images to /home/garage/Documents/jin-summer24/Sentinel_Summer24/nz-trailcams-test/downsized_data/symlinks-nz-trailcams-acc-aiv/error_images.json\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create `labels.txt` to contain all unique classes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# save all unique labels to labels.txt\n",
    "labels_path = f\"{datapath}/labels.txt\"\n",
    "with open(labels_path, 'w') as f:\n",
    "    for label in set(species.values()):\n",
    "        f.write(f\"{label}\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Label!\n",
    "This section generates a command `cmd` to be copy and pasted into a terminal. Before running this command in the terminal, set up and activate a conda environment for labelme as follows: \n",
    "```\n",
    "git clone https://github.com/agentmorris/labelme\n",
    "cd labelme\n",
    "conda create -n labelme python=3.11 pip -y\n",
    "conda activate labelme\n",
    "pip install -e .\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Label one chunk\n",
    "\n",
    "# Specifically, generate the command to start labelme, pointed at this chunk, and copy that\n",
    "# command to the clipboard.\n",
    "\n",
    "i_chunk = 0\n",
    "resume = True\n",
    "\n",
    "chunk_folder_abs = os.path.join(chunk_folder_base,'chunk_{}'.format(\n",
    "    str(i_chunk).zfill(3)))\n",
    "assert os.path.isdir(chunk_folder_abs)\n",
    "\n",
    "flags = ['ignore','empty']\n",
    "\n",
    "flag_file = os.path.join(chunk_folder_abs,'flags.txt')\n",
    "with open(flag_file,'w') as f:\n",
    "    for flag in flags:        \n",
    "        f.write(flag + '\\n')\n",
    "\n",
    "last_updated_file = os.path.join(chunk_folder_abs,'labelme_last_updated.txt')\n",
    "cmd = f'python {labelme_path}/labelme {chunk_folder_abs} --labels {labels_path} --linewidth 12 --last_updated_file {last_updated_file} --flags {flag_file}'\n",
    "if resume:\n",
    "    cmd += ' --resume_from_last_update'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# # the following code causes an error in loading the Qt platform plugin, since it is seemingly incompatible with some\n",
    "# # packages installed in the megadetector environment used to run this notebook\n",
    "# os.system(cmd)\n",
    "\n",
    "# instead, manually copy the following printed command and run it in the terminal \n",
    "# (after activating conda environment labelme)\n",
    "print(cmd)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "python /home/garage/Documents/jin-summer24/labelme/labelme /home/garage/Documents/jin-summer24/Sentinel_Summer24/nz-trailcams-test/downsized_data/symlinks-nz-trailcams-acc-aiv/chunk_000 --labels /home/garage/Documents/jin-summer24/Sentinel_Summer24/nz-trailcams-test/downsized_data/labels.txt --linewidth 12 --last_updated_file /home/garage/Documents/jin-summer24/Sentinel_Summer24/nz-trailcams-test/downsized_data/symlinks-nz-trailcams-acc-aiv/chunk_000/labelme_last_updated.txt --flags /home/garage/Documents/jin-summer24/Sentinel_Summer24/nz-trailcams-test/downsized_data/symlinks-nz-trailcams-acc-aiv/chunk_000/flags.txt --resume_from_last_update\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Labelme to MD: convert updated annotations into MD format "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# to check for updates from labelme\n",
    "ppresults = process_batch_results(options)\n",
    "html_output_file = ppresults.output_html_file\n",
    "path_utils.open_file(html_output_file,attempt_to_open_in_wsl_host=True,browser_name='chrome')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading results from /home/garage/Documents/jin-summer24/Sentinel_Summer24/nz-trailcams-test/postprocessing/nz-trailcams-aac-aiv/nz-trailcams-aac-aiv-2024-jun-07-v5a.0.0/combined_api_outputs/nz-trailcams-aac-aiv-2024-jun-07-v5a.0.0_detections.filtered_rde_0.100_0.850_15_0.200.json\n",
      "Converting results to dataframe\n",
      "Finished loading MegaDetector results for 38 images from /home/garage/Documents/jin-summer24/Sentinel_Summer24/nz-trailcams-test/postprocessing/nz-trailcams-aac-aiv/nz-trailcams-aac-aiv-2024-jun-07-v5a.0.0/combined_api_outputs/nz-trailcams-aac-aiv-2024-jun-07-v5a.0.0_detections.filtered_rde_0.100_0.850_15_0.200.json\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|| 38/38 [00:00<00:00, 12762.94it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished loading and preprocessing 38 rows from detector output, predicted 36 positives.\n",
      "...and 0 almost-positives\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Rendering images with 30 processes\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|| 38/38 [00:00<00:00, 253.52it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Rendered 38 images (of 38) in 1.57 seconds (0.04 seconds per image)\n",
      "Finished writing html to /home/garage/Documents/jin-summer24/Sentinel_Summer24/nz-trailcams-test/postprocessing/nz-trailcams-aac-aiv/nz-trailcams-aac-aiv-2024-jun-07-v5a.0.0/preview/nz-trailcams-aac-aiv-2024-jun-07-v5a.0.0_rde_0.100_0.850_15_0.200_0.200/index.html\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37e97609861194f3846f147cecf47c547a248e60dbda7654758428b266b5a777"
  },
  "kernelspec": {
   "display_name": "Python 3.11.9 64-bit ('megadetector': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}